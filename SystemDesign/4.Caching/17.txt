# Cache Eviction Policies â€” LRU, LFU, FIFO

## Why eviction exists (start here)

Cache is **finite**.

When cache is full and a new item comes:

> **Something must be removed**

Eviction policy answers:

* *What gets removed?*
* *Why that item?*
* *What breaks if we choose wrong?*

---

## 1ï¸âƒ£ FIFO â€” First In, First Out

### How it works

* Oldest inserted item is removed
* Access frequency **does not matter**

Queue behavior:

```
Put A â†’ Put B â†’ Put C
Cache full
Put D â†’ Evict A
```

---

### Pros

âœ” Very simple
âœ” Low overhead

---

### Cons (important)

âŒ Ignores usage
âŒ Hot data can be evicted
âŒ Bad for real traffic patterns

---

### Real-world analogy

A queue at a ticket counter:

* Doesnâ€™t care who needs it most
* Just who came first

---

### When FIFO makes sense

Almost **never** in modern systems.

Maybe:

* Very predictable batch workloads
* Extremely simple cache layers

ðŸ‘‰ For Redis â†’ **not recommended**

---

## 2ï¸âƒ£ LRU â€” Least Recently Used (MOST COMMON)

### How it works

Evicts the item **not used for the longest time**

```
Access order:
A â†’ B â†’ C â†’ A â†’ D

Least recently used = B
Evict B
```

---

### Key idea

> â€œRecent past predicts near futureâ€

This matches **real user behavior**.

---

### Pros

âœ” Great general-purpose policy
âœ” Simple mental model
âœ” Works well for APIs & web traffic

---

### Cons

âŒ One-time scans can poison cache
âŒ Frequency not considered

Example:

* User opens massive report once
* Evicts many small hot items

---

### Redis support

```conf
maxmemory-policy allkeys-lru
```

---

### Best use cases

âœ” API responses
âœ” Product lists
âœ” Config data
âœ” User session data

---

## 3ï¸âƒ£ LFU â€” Least Frequently Used (SMART but COSTLY)

### How it works

Evicts item used **least number of times**

```
Access counts:
A = 100
B = 80
C = 2

Evict C
```

---

### Key idea

> â€œPopularity matters more than recencyâ€

---

### Pros

âœ” Protects hot data
âœ” Great for long-lived popular items
âœ” Resists cache pollution

---

### Cons

âŒ Higher memory overhead
âŒ Old popular data may stay forever
âŒ Slightly slower than LRU

Redis fixes this with **decaying counters**.

---

### Redis support

```conf
maxmemory-policy allkeys-lfu
```

---

### Best use cases

âœ” Product catalogs
âœ” Category lists
âœ” Master data
âœ” Popular dashboards

---

## 4ï¸âƒ£ Side-by-side comparison

| Policy | Evicts         | Strength | Weakness       |
| ------ | -------------- | -------- | -------------- |
| FIFO   | Oldest         | Simple   | Dumb           |
| LRU    | Least recent   | Balanced | Scan pollution |
| LFU    | Least frequent | Smart    | Overhead       |

---

## 5ï¸âƒ£ Redis eviction policy options (important)

| Policy       | Meaning          |
| ------------ | ---------------- |
| noeviction   | âŒ Fail writes    |
| allkeys-lru  | LRU for all keys |
| allkeys-lfu  | LFU for all keys |
| volatile-lru | LRU for TTL keys |
| volatile-lfu | LFU for TTL keys |
| volatile-ttl | Nearest expiry   |

**Production default (common):**

```conf
allkeys-lru
```

---

## 6ï¸âƒ£ What YOU should use (POS system)

### Financial data (JV, AR, BS)

* TTL: short
* Pattern: bursty
* Requirement: correctness > speed

âœ… **LRU + short TTL**

---

### Master data (products, categories)

* Long-lived
* Popular
* Rarely changes

âœ… **LFU**

---

### Sessions / tokens

* TTL-based
* Security-sensitive

âœ… **volatile-lru**

---

## 7ï¸âƒ£ Cache poisoning (critical insight)

LRU can be broken by:

* Large one-time queries
* Bulk exports
* Admin reports

Fix:

* Separate Redis instances
* Separate key namespaces
* LFU for master data

---

## 8ï¸âƒ£ What happens when eviction goes wrong

âŒ Hot data evicted â†’ DB overload
âŒ Redis thrashing â†’ latency spikes
âŒ Finance reports inconsistent
âŒ â€œWorks in dev, fails in prodâ€

Eviction bugs are **silent killers**.

---

## 9ï¸âƒ£ Interview-ready explanation (say this)

> Cache eviction defines which entries are removed when memory is full. LRU removes least recently used items and fits most web traffic. LFU removes least frequently used items and protects hot data. FIFO is simple but usually inefficient. Choosing eviction policy depends on access patterns and data criticality.

---

## Brutal truth (important for you)

If you donâ€™t:

* size Redis properly
* choose eviction intentionally
* segment cache by data type

Then eviction will **decide your system behavior randomly**.

And randomness in finance systems = disaster.